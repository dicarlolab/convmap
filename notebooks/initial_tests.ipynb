{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common attributes, forcing a renaming ...\n",
      "Using default renamer ...\n",
      "('Replacing columns', ['rxz', 'rxy', 'ryz'])\n",
      "common attributes, forcing a renaming ...\n",
      "Using default renamer ...\n",
      "('Replacing columns', ['rxz', 'rxy', 'ryz'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "# sys.path.insert(0, '/Users/pouyabashivan/Dropbox (MIT)/Codes/dldata')\n",
    "import dldata.metrics.utils as utils\n",
    "import dldata.stimulus_sets.hvm as hvm\n",
    "import cPickle\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed([0])\n",
    "from dldata.physiology.hongmajaj.mappings import CHANNEL_INFO\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.misc import imread\n",
    "from scipy.stats import pearsonr\n",
    "np.random.seed(123)\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "%matplotlib inline\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops       \n",
    "import scipy.stats as stats\n",
    "\n",
    "sys.path.insert(0, '/braintree/home/bashivan/dropbox/Codes/Retina/misc/Models/')\n",
    "from metrics_expert import MetricsExpert\n",
    "analyst = MetricsExpert('/braintree/data2/active/users/bashivan/model_features/alexnet_model_139k.hdf5',\n",
    "                        '/braintree/data2/active/users/bashivan/tmp',\n",
    "                        'IT')\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 14, \"ytick.major.size\": 14})\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "\n",
    "dataset_hvm = hvm.HvMWithDiscfade()\n",
    "meta_hvm = dataset_hvm.meta\n",
    "neural_fea = np.array(dataset_hvm.neuronal_features)\n",
    "neural_reps = dataset_hvm.get_neuronal_feature_reps()['V6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.interpolate import griddata, interp2d\n",
    "\n",
    "\n",
    "def reps_to_array(reps):\n",
    "    \"\"\"\n",
    "    reps: dictionary containing the reps for each variation level  \n",
    "    \"\"\"\n",
    "    max_reps = np.max([reps[i].shape[0] for i in reps.keys()], axis=0)\n",
    "    hvm_neural = np.zeros((max_reps, 5760, reps['V0'].shape[2]))\n",
    "    hvm_neural[...] = np.NaN\n",
    "\n",
    "    c = 0\n",
    "    for key in reps:\n",
    "        shape = reps[key].shape\n",
    "        hvm_neural[:shape[0], c:c+shape[1], :] = reps[key]\n",
    "        c += shape[1]\n",
    "    return hvm_neural\n",
    "\n",
    "\n",
    "def concat_reps(rep_list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    max_reps = np.max([r.shape[0] for r in rep_list])\n",
    "    resized_reps = []\n",
    "    for r in rep_list:\n",
    "        tmp = np.zeros((max_reps, r.shape[1], r.shape[2]))\n",
    "        tmp[...] = np.NaN\n",
    "        tmp[:r.shape[0], :, :] = r\n",
    "        resized_reps.append(tmp)\n",
    "    return np.concatenate(resized_reps, axis=-1)\n",
    "\n",
    "def fix_nan_reps(reps):\n",
    "    \"\"\"Some of the entries in neural reps might be nan. \n",
    "    Substitute those values by the average response of \n",
    "    corresponding neurons to all images over all valid reps.\n",
    "    reps = [n_reps, n_samples, n_neurons]\n",
    "    \"\"\"\n",
    "    if np.any(np.isnan(reps)):\n",
    "        # find the indices of nan neurons\n",
    "        nan_ind = np.isnan(reps)\n",
    "        _, _, nan_neu_ind = np.nonzero(nan_ind)\n",
    "\n",
    "        corrected_reps = reps\n",
    "        for n in np.unique(nan_neu_ind):\n",
    "            # create a mask of all nan values for a neuron\n",
    "            mask = np.zeros(shape=nan_ind.shape, dtype=bool)\n",
    "            mask[:, :, n] = True\n",
    "            masked_nan_ind = nan_ind & mask\n",
    "\n",
    "            # substitue all nan values of neuron by average neuron response\n",
    "            av_neuron_act = np.nanmean(reps[:, :, n])\n",
    "            corrected_reps[masked_nan_ind] = av_neuron_act\n",
    "        return corrected_reps\n",
    "    else:\n",
    "        return reps\n",
    "\n",
    "def project_reps(input_reps, W_mat):\n",
    "    \"\"\"Project each rep of neural data using the projection matrix\n",
    "    input_reps = [n_reps, n_samples, n_neurons]\"\"\"\n",
    "    input_reps = fix_nan_reps(input_reps)\n",
    "    reps = []\n",
    "    for rep in input_reps:\n",
    "        reps.append(scale(rep))\n",
    "    comp_reps = np.tensordot(reps, W_mat, axes=1)\n",
    "    return comp_reps\n",
    "\n",
    "def fit_reg(X, Y):\n",
    "    \"\"\"\n",
    "    Fits a linear regression model to the data and returns regression model with score and predictions\"\"\"\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, Y)\n",
    "    preds = reg.predict(X)\n",
    "    score = pearsonr(Y, preds)\n",
    "    return reg, score, preds\n",
    "\n",
    "def predict_outputs(features, weights):\n",
    "    \"\"\"\n",
    "    Predict outputs given input features and weights.\"\"\"\n",
    "    model_pcs = np.matmul(features - weights['pca_b'], weights['pca_w'])\n",
    "    preds = np.matmul(model_pcs, weights['pls_w']) + weights['pls_b'] \n",
    "    return preds\n",
    "\n",
    "\n",
    "def resize_mat(mat, new_size):\n",
    "    \"\"\"\n",
    "    Resize a matrix to the desired size. Input size is [num_channels, num_pixels, num_pixels]\"\"\"\n",
    "    if mat.ndim==2:\n",
    "        mat = np.expand_dims(mat, axis=0)\n",
    "    num_ch, _, num_pix = np.array(mat).shape\n",
    "\n",
    "    x = np.arange(0, num_pix)\n",
    "    y = np.arange(0, num_pix)\n",
    "    ratio = (new_size - 1.) / (num_pix - 1)\n",
    "\n",
    "    x_new = np.arange(0, new_size)\n",
    "    y_new = np.arange(0, new_size)\n",
    "\n",
    "    output = []\n",
    "    for i in range(num_ch):\n",
    "        resized_rf_func = interp2d(x * ratio, y * ratio, mat[i], kind='cubic')\n",
    "        tmp_out = resized_rf_func(x_new, y_new)\n",
    "        output.append(tmp_out)\n",
    "\n",
    "    return np.squeeze(output)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separable (Mask-Mix) Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load V6 ids\n",
    "# ids = np.nonzero(meta_hvm['var'] == 'V6')[0]\n",
    "# len(ids)\n",
    "\n",
    "# Ko 640 ids\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('/braintree/home/bashivan/dropbox/Data/dimensionality/Ko_data/V4_data/mag_left_v4.mat')\n",
    "images_lookup = loadmat('/braintree/home/bashivan/dropbox/Data/dimensionality/Ko_data/id_object_lookup.mat')['id_object_lookup']\n",
    "# site_locations = loadmat('/braintree/home/bashivan/dropbox/Data/Ko_data/V4_data/kk_2_pb_sites.mat')\n",
    "\n",
    "# Find matching image ids on HVM\n",
    "ids = []\n",
    "for r in images_lookup:\n",
    "    image_num = int(np.nonzero(meta_hvm['id'] == r[1])[0])\n",
    "    ids.append(image_num)\n",
    "\n",
    "# All ids\n",
    "# ids = range(5760)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey='magneto'\n",
    "v4_data_reps_hvm = h5py.File('/braintree/data2/active/common/for_pouya/season7/{0}/mapHVM_640/rate_img.mat'.format(monkey))\n",
    "v4_data_reps_hvm = np.array(v4_data_reps_hvm['rate_img']).transpose(2, 0, 1)\n",
    "\n",
    "v4_norm_reps_hvm = h5py.File('/braintree/data2/active/common/for_pouya/season7/{0}/mapHVM_640/rate_norm.mat'.format(monkey))\n",
    "v4_norm_reps_hvm = np.array(v4_norm_reps_hvm['rate_norm']).transpose(2, 0, 1)\n",
    "\n",
    "# Normalize responses    \n",
    "bias = np.nanmean(v4_norm_reps_hvm, axis=0).mean(0)\n",
    "std = np.nanmean(v4_norm_reps_hvm, axis=0).std(0)\n",
    "neural_reps = (v4_data_reps_hvm - bias)/std\n",
    "neural_fea = np.nanmean(neural_reps, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores: ', 0.6797741056401212)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.6575022540610389)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "n_comps = 1000\n",
    "area = 'it'  # v4 or it\n",
    "\n",
    "# if area == 'v4':\n",
    "#     neuron_ids = dataset_hvm.V4_NEURONS\n",
    "#     layer_name = 'mdl_conv3'\n",
    "# else:\n",
    "#     neuron_ids = dataset_hvm.IT_NEURONS\n",
    "#     layer_name = 'mdl_fc6'\n",
    "neuron_ids = range(96)\n",
    "    \n",
    "features_h5_hvm = h5py.File('/braintree/data2/active/users/bashivan/model_features/alexnet_retina299_input299_out299.h5')\n",
    "pca_neural = PCA(whiten=True, n_components=20)\n",
    "\n",
    "# features = np.array(features_h5_hvm[layer_name])[ids, :]\n",
    "# features = features.reshape(features.shape[0], -1)\n",
    "# pca = PCA(n_components=n_comps, whiten=False)\n",
    "# model_pcs = pca.fit_transform(features)\n",
    "\n",
    "# neural_fr = neural_fea[ids][:, neuron_ids]\n",
    "neural_fr = neural_fea\n",
    "\n",
    "clf = linear_model.Ridge(alpha=10)\n",
    "\n",
    "np.random.seed(0)\n",
    "num_images = features.shape[0]\n",
    "# train_ind = np.random.choice(range(num_images), num_images * 9 // 10, replace=False)\n",
    "train_ind = np.random.choice(range(num_images), num_images // 2, replace=False)\n",
    "test_ind = np.nonzero(~ np.in1d(range(num_images), train_ind))[0]\n",
    "\n",
    "clf.fit(model_pcs[train_ind], neural_fr[train_ind])\n",
    "\n",
    "# print the test performance \n",
    "hvm_preds = clf.predict(model_pcs[test_ind])\n",
    "hvm_scores = np.array([pearsonr(hvm_preds[:, i], neural_fr[test_ind, i])[0] for i in range(hvm_preds.shape[-1])])\n",
    "\n",
    "consistency = np.array(analyst.compute_consistency(neural_reps[:, :, neuron_ids], 20, population=False)).mean(1)\n",
    "print('Scores: ', np.median(hvm_scores))\n",
    "print('Consistency: ', np.median(consistency)) \n",
    "print('Norm. EV: ', np.median(hvm_scores ** 2 / consistency ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping with ls=15, ld=15\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 7725.53, Reg Loss: 23623.11\n",
      "Epoch: 101, Err Loss: 33.33, Reg Loss: 39.11\n",
      "Epoch: 201, Err Loss: 29.35, Reg Loss: 36.20\n",
      "Epoch: 301, Err Loss: 29.91, Reg Loss: 18.33\n",
      "Epoch: 401, Err Loss: 27.39, Reg Loss: 18.34\n",
      "Epoch: 501, Err Loss: 26.96, Reg Loss: 17.70\n",
      "Epoch: 601, Err Loss: 32.76, Reg Loss: 17.71\n",
      "('Scores: ', 0.4982847943552707)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.417687094234107)\n",
      "Mapping with ls=15, ld=20\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 6248.42, Reg Loss: 23193.62\n",
      "Epoch: 101, Err Loss: 35.25, Reg Loss: 42.25\n",
      "Epoch: 201, Err Loss: 25.36, Reg Loss: 39.43\n",
      "Epoch: 301, Err Loss: 28.74, Reg Loss: 22.45\n",
      "Epoch: 401, Err Loss: 28.37, Reg Loss: 22.57\n",
      "Epoch: 501, Err Loss: 26.42, Reg Loss: 22.08\n",
      "Epoch: 601, Err Loss: 26.88, Reg Loss: 22.12\n",
      "('Scores: ', 0.49742021156160965)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.394521432336193)\n",
      "Mapping with ls=15, ld=50\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 6237.34, Reg Loss: 23032.77\n",
      "Epoch: 101, Err Loss: 33.58, Reg Loss: 68.42\n",
      "Epoch: 201, Err Loss: 27.89, Reg Loss: 61.72\n",
      "Epoch: 301, Err Loss: 30.86, Reg Loss: 44.59\n",
      "Epoch: 401, Err Loss: 27.41, Reg Loss: 44.01\n",
      "Epoch: 501, Err Loss: 27.70, Reg Loss: 43.44\n",
      "Epoch: 601, Err Loss: 27.79, Reg Loss: 43.27\n",
      "('Scores: ', 0.5148185253380533)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.43959635433228467)\n",
      "Mapping with ls=20, ld=15\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 6946.75, Reg Loss: 32542.19\n",
      "Epoch: 101, Err Loss: 31.99, Reg Loss: 46.50\n",
      "Epoch: 201, Err Loss: 31.18, Reg Loss: 44.12\n",
      "Epoch: 301, Err Loss: 31.30, Reg Loss: 18.90\n",
      "Epoch: 401, Err Loss: 31.69, Reg Loss: 18.92\n",
      "Epoch: 501, Err Loss: 30.04, Reg Loss: 18.24\n",
      "Epoch: 601, Err Loss: 29.24, Reg Loss: 18.28\n",
      "('Scores: ', 0.45048469530555857)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.38960938816306045)\n",
      "Mapping with ls=20, ld=20\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 5813.44, Reg Loss: 31285.76\n",
      "Epoch: 101, Err Loss: 35.25, Reg Loss: 50.95\n",
      "Epoch: 201, Err Loss: 29.05, Reg Loss: 47.03\n",
      "Epoch: 301, Err Loss: 29.17, Reg Loss: 23.11\n",
      "Epoch: 401, Err Loss: 26.93, Reg Loss: 23.01\n",
      "Epoch: 501, Err Loss: 30.63, Reg Loss: 22.39\n",
      "Epoch: 601, Err Loss: 28.83, Reg Loss: 22.36\n",
      "('Scores: ', 0.5139067791730592)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.3983870149197938)\n",
      "Mapping with ls=20, ld=50\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 6439.46, Reg Loss: 31350.01\n",
      "Epoch: 101, Err Loss: 33.93, Reg Loss: 76.41\n",
      "Epoch: 201, Err Loss: 29.99, Reg Loss: 70.59\n",
      "Epoch: 301, Err Loss: 26.96, Reg Loss: 45.99\n",
      "Epoch: 401, Err Loss: 28.48, Reg Loss: 45.37\n",
      "Epoch: 501, Err Loss: 24.99, Reg Loss: 44.63\n",
      "Epoch: 601, Err Loss: 29.62, Reg Loss: 44.51\n",
      "('Scores: ', 0.5031302707284705)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.39748793552106065)\n",
      "Mapping with ls=50, ld=15\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 6650.86, Reg Loss: 79959.84\n",
      "Epoch: 101, Err Loss: 30.54, Reg Loss: 95.77\n",
      "Epoch: 201, Err Loss: 29.13, Reg Loss: 88.89\n",
      "Epoch: 301, Err Loss: 33.02, Reg Loss: 20.64\n",
      "Epoch: 401, Err Loss: 35.10, Reg Loss: 20.91\n",
      "Epoch: 501, Err Loss: 35.15, Reg Loss: 15.80\n",
      "Epoch: 601, Err Loss: 37.72, Reg Loss: 15.82\n",
      "('Scores: ', 0.3398557380782993)\n",
      "('Consistency: ', 0.8560523943000633)\n",
      "('Norm. EV: ', 0.31315885013968475)\n",
      "Mapping with ls=50, ld=20\n",
      "Initializing...\n",
      "Epoch: 1, Err Loss: 7070.67, Reg Loss: 78407.14\n",
      "Epoch: 101, Err Loss: 30.97, Reg Loss: 102.20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-93b9dc676a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                               \u001b[0mmap_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                              )\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/dropbox/Codes/cube_mapping/cubemap/sep_map.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    186\u001b[0m                        self._lr_ph: self._lr}\n\u001b[1;32m    187\u001b[0m           _, loss_value, reg_loss_value = self._sess.run([self.train_op, self.l2_error, self.reg_loss],\n\u001b[0;32m--> 188\u001b[0;31m                                                          feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_rate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m           \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %d, Err Loss: %.2f, Reg Loss: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import h5py\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/braintree/home/bashivan/dropbox/Codes/cube_mapping/cubemap/')\n",
    "from sep_map import SeparableMap\n",
    "# from cubemap.sep_map import SeparableMap\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "map_type = 'separable'   # 'linreg' or 'separable'\n",
    "area = 'it'  # v4 or it\n",
    "\n",
    "# if area == 'v4':\n",
    "#     neuron_ids = dataset_hvm.V4_NEURONS\n",
    "#     layer_name = 'mdl_conv3'\n",
    "# else:\n",
    "#     neuron_ids = dataset_hvm.IT_NEURONS\n",
    "#     layer_name = 'mdl_pool5'\n",
    "neuron_ids = range(96)\n",
    "\n",
    "# features_h5_hvm = h5py.File('/braintree/data2/active/users/bashivan/model_features/alexnet_retina299_input299_out299.h5')\n",
    "# feats = np.array(features_h5_hvm[layer_name])[ids, :]\n",
    "\n",
    "# neurons = neural_fea[ids][:, neuron_ids]\n",
    "neurons = neural_fea\n",
    "\n",
    "if map_type == 'linreg':\n",
    "    X = pca_feats\n",
    "else:\n",
    "    X = feats\n",
    "# Y = scale(neurons)\n",
    "Y = neurons\n",
    "\n",
    "num_images = X.shape[0]\n",
    "np.random.seed(0)\n",
    "# train_ind = np.random.choice(range(num_images), num_images * 9 // 10, replace=False)\n",
    "train_ind = np.random.choice(range(num_images), num_images // 2, replace=False)\n",
    "test_ind = np.nonzero(~ np.in1d(range(num_images), train_ind))[0]\n",
    "\n",
    "all_scores = np.zeros((3, 3))\n",
    "consistency = np.array(analyst.compute_consistency(neural_reps, 20, population=False)).mean(1)\n",
    "\n",
    "for ls_ind, ls in enumerate([15, 20, 50]): \n",
    "    for ld_ind, ld in enumerate([15, 20, 50]):\n",
    "        print('Mapping with ls={}, ld={}'.format(ls, ld))\n",
    "        mapper = SeparableMap(graph=None, max_epochs=700 // 1, tol=0.1, \n",
    "                              init_lr=0.01, batch_size=50, ls=ls, ld=ld, num_neurons=neurons.shape[-1],\n",
    "                              map_type=map_type, inits=None, decay_rate=200 // 1, log_rate=100 // 1\n",
    "                             )\n",
    "        mapper.fit(X[train_ind], Y[train_ind])\n",
    "        preds = mapper.predict(X[test_ind])\n",
    "        scores = np.array([pearsonr(preds[:, i], Y[test_ind, i])[0] for i in range(preds.shape[-1])])\n",
    "        all_scores[ls_ind, ld_ind] = np.median(scores)\n",
    "        \n",
    "        print('Scores: ', np.median(scores))\n",
    "        print('Consistency: ', np.median(consistency)) \n",
    "        print('Norm. EV: ', np.median(scores ** 2 / consistency ** 2))\n",
    "\n",
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
