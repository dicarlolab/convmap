{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "# sys.path.insert(0, '/Users/pouyabashivan/Dropbox (MIT)/Codes/dldata')\n",
    "import dldata.metrics.utils as utils\n",
    "import dldata.stimulus_sets.hvm as hvm\n",
    "import cPickle\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed([0])\n",
    "from dldata.physiology.hongmajaj.mappings import CHANNEL_INFO\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.misc import imread\n",
    "\n",
    "np.random.seed(123)\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "%matplotlib inline\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops       \n",
    "import scipy.stats as stats\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 14, \"ytick.major.size\": 14})\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "\n",
    "dataset_hvm = hvm.HvMWithDiscfade()\n",
    "meta_hvm = dataset_hvm.meta\n",
    "neural_fea = np.array(dataset_hvm.neuronal_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.interpolate import griddata, interp2d\n",
    "\n",
    "\n",
    "def reps_to_array(reps):\n",
    "    \"\"\"\n",
    "    reps: dictionary containing the reps for each variation level  \n",
    "    \"\"\"\n",
    "    max_reps = np.max([reps[i].shape[0] for i in reps.keys()], axis=0)\n",
    "    hvm_neural = np.zeros((max_reps, 5760, reps['V0'].shape[2]))\n",
    "    hvm_neural[...] = np.NaN\n",
    "\n",
    "    c = 0\n",
    "    for key in reps:\n",
    "        shape = reps[key].shape\n",
    "        hvm_neural[:shape[0], c:c+shape[1], :] = reps[key]\n",
    "        c += shape[1]\n",
    "    return hvm_neural\n",
    "\n",
    "\n",
    "def concat_reps(rep_list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    max_reps = np.max([r.shape[0] for r in rep_list])\n",
    "    resized_reps = []\n",
    "    for r in rep_list:\n",
    "        tmp = np.zeros((max_reps, r.shape[1], r.shape[2]))\n",
    "        tmp[...] = np.NaN\n",
    "        tmp[:r.shape[0], :, :] = r\n",
    "        resized_reps.append(tmp)\n",
    "    return np.concatenate(resized_reps, axis=-1)\n",
    "\n",
    "def fix_nan_reps(reps):\n",
    "    \"\"\"Some of the entries in neural reps might be nan. \n",
    "    Substitute those values by the average response of \n",
    "    corresponding neurons to all images over all valid reps.\n",
    "    reps = [n_reps, n_samples, n_neurons]\n",
    "    \"\"\"\n",
    "    if np.any(np.isnan(reps)):\n",
    "        # find the indices of nan neurons\n",
    "        nan_ind = np.isnan(reps)\n",
    "        _, _, nan_neu_ind = np.nonzero(nan_ind)\n",
    "\n",
    "        corrected_reps = reps\n",
    "        for n in np.unique(nan_neu_ind):\n",
    "            # create a mask of all nan values for a neuron\n",
    "            mask = np.zeros(shape=nan_ind.shape, dtype=bool)\n",
    "            mask[:, :, n] = True\n",
    "            masked_nan_ind = nan_ind & mask\n",
    "\n",
    "            # substitue all nan values of neuron by average neuron response\n",
    "            av_neuron_act = np.nanmean(reps[:, :, n])\n",
    "            corrected_reps[masked_nan_ind] = av_neuron_act\n",
    "        return corrected_reps\n",
    "    else:\n",
    "        return reps\n",
    "\n",
    "def project_reps(input_reps, W_mat):\n",
    "    \"\"\"Project each rep of neural data using the projection matrix\n",
    "    input_reps = [n_reps, n_samples, n_neurons]\"\"\"\n",
    "    input_reps = fix_nan_reps(input_reps)\n",
    "    reps = []\n",
    "    for rep in input_reps:\n",
    "        reps.append(scale(rep))\n",
    "    comp_reps = np.tensordot(reps, W_mat, axes=1)\n",
    "    return comp_reps\n",
    "\n",
    "def fit_reg(X, Y):\n",
    "    \"\"\"\n",
    "    Fits a linear regression model to the data and returns regression model with score and predictions\"\"\"\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, Y)\n",
    "    preds = reg.predict(X)\n",
    "    score = pearsonr(Y, preds)\n",
    "    return reg, score, preds\n",
    "\n",
    "def predict_outputs(features, weights):\n",
    "    \"\"\"\n",
    "    Predict outputs given input features and weights.\"\"\"\n",
    "    model_pcs = np.matmul(features - weights['pca_b'], weights['pca_w'])\n",
    "    preds = np.matmul(model_pcs, weights['pls_w']) + weights['pls_b'] \n",
    "    return preds\n",
    "\n",
    "\n",
    "def resize_mat(mat, new_size):\n",
    "    \"\"\"\n",
    "    Resize a matrix to the desired size. Input size is [num_channels, num_pixels, num_pixels]\"\"\"\n",
    "    if mat.ndim==2:\n",
    "        mat = np.expand_dims(mat, axis=0)\n",
    "    num_ch, _, num_pix = np.array(mat).shape\n",
    "\n",
    "    x = np.arange(0, num_pix)\n",
    "    y = np.arange(0, num_pix)\n",
    "    ratio = (new_size - 1.) / (num_pix - 1)\n",
    "\n",
    "    x_new = np.arange(0, new_size)\n",
    "    y_new = np.arange(0, new_size)\n",
    "\n",
    "    output = []\n",
    "    for i in range(num_ch):\n",
    "        resized_rf_func = interp2d(x * ratio, y * ratio, mat[i], kind='cubic')\n",
    "        tmp_out = resized_rf_func(x_new, y_new)\n",
    "        output.append(tmp_out)\n",
    "\n",
    "    return np.squeeze(output)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Left Magneto data and ID lookup dictionary (corresponding ids from hvm 5760 images)\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('/braintree/home/bashivan/dropbox/Data/Ko_data/V4_data/mag_left_v4.mat')\n",
    "images_lookup = loadmat('/braintree/home/bashivan/dropbox/Data/Ko_data/id_object_lookup.mat')['id_object_lookup']\n",
    "# site_locations = loadmat('/braintree/home/bashivan/dropbox/Data/Ko_data/V4_data/kk_2_pb_sites.mat')\n",
    "\n",
    "# Find matching image ids on HVM\n",
    "ids = []\n",
    "for r in images_lookup:\n",
    "    image_num = int(np.nonzero(meta_hvm['id'] == r[1])[0])\n",
    "    ids.append(image_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separable (Mask-Mix) Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import h5py\n",
    "from scipy.stats import pearsonr\n",
    "from cubemap.sep_map import SeparableMap\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "map_type = 'separable'   # 'linreg' or 'separable'\n",
    "\n",
    "features_h5_hvm = h5py.File('/braintree/data2/active/users/bashivan/model_features/alexnet_retina299_input299_out299.h5')\n",
    "# features_h5_coco = h5py.File('/braintree/data2/active/users/bashivan/model_features/alexnet_coco_retina299_input299_out299.h5')\n",
    "\n",
    "features_hvm = np.array(features_h5_hvm['mdl_conv3'])[ids, :]\n",
    "# features_coco = np.array(features_h5_hvm['mdl_conv3'])[:640, :]\n",
    "\n",
    "# feats = np.concatenate((features_hvm, features_coco), axis=0)\n",
    "\n",
    "feats = features_hvm\n",
    "neurons = np.nanmean(v4_data_reps, axis=0)\n",
    "\n",
    "if map_type == 'linreg':\n",
    "    X = pca_feats\n",
    "else:\n",
    "    X = feats\n",
    "Y = scale(neurons)\n",
    "    \n",
    "num_images = X.shape[0]\n",
    "np.random.seed(0)\n",
    "train_ind = np.random.choice(range(num_images), num_images * 9 // 10, replace=False)\n",
    "test_ind = np.nonzero(~ np.in1d(range(num_images), train_ind))[0]\n",
    "\n",
    "all_scores = np.zeros((3, 3))\n",
    "# consistency = np.array(analyst.compute_consistency(v4_data_reps, 20, population=False)).mean(1)\n",
    "\n",
    "for ls_ind, ls in enumerate([0.4]): \n",
    "    for ld_ind, ld in enumerate([0.3]):\n",
    "        print('Mapping with ls={}, ld={}'.format(ls, ld))\n",
    "        mapper = SeparableMap(graph=None, max_epochs=700, tol=0.1, \n",
    "                              init_lr=0.01, batch_size=50, ls=ls, ld=ld, num_neurons=num_select_cells,\n",
    "                              map_type=map_type, inits=None, decay_rate=200, log_rate=100\n",
    "                             )\n",
    "        mapper.fit(X[train_ind], Y[train_ind])\n",
    "        preds = mapper.predict(X[test_ind])\n",
    "        scores = np.array([pearsonr(preds[:, i], Y[test_ind, i])[0] for i in range(preds.shape[-1])])\n",
    "        all_scores[ls_ind, ld_ind] = np.median(scores)\n",
    "        \n",
    "        print('Scores: ', np.median(scores))\n",
    "#         print('Consistency: ', np.median(consistency)) \n",
    "        print('Norm. EV: ', np.median(scores ** 2 / consistency ** 2))\n",
    "\n",
    "print(all_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
